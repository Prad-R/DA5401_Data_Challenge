{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T17:32:17.789161Z",
     "iopub.status.busy": "2025-11-19T17:32:17.788624Z",
     "iopub.status.idle": "2025-11-19T17:32:17.793473Z",
     "shell.execute_reply": "2025-11-19T17:32:17.792652Z",
     "shell.execute_reply.started": "2025-11-19T17:32:17.789139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T15:51:06.947453Z",
     "iopub.status.busy": "2025-11-19T15:51:06.946766Z",
     "iopub.status.idle": "2025-11-19T15:51:20.919698Z",
     "shell.execute_reply": "2025-11-19T15:51:20.918826Z",
     "shell.execute_reply.started": "2025-11-19T15:51:06.947425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 15:51:12.118306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763567472.141444     300 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763567472.148473     300 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# !pip install protobuf==3.20.3\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model for embedding text\n",
    "# Git doesn't allow addition of my ow token.\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", token=\"USE_TOKEN\")\n",
    "\n",
    "# Encode the metric\n",
    "metric_embeddings = np.load('/kaggle/input/dataset/metric_name_embeddings.npy')\n",
    "\n",
    "with open('/kaggle/input/dataset/metric_names.json', 'r') as f:\n",
    "    metric_names = json.load(f)\n",
    "\n",
    "metric_to_index_map =  {name: i for i, name in enumerate(metric_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T15:51:20.920837Z",
     "iopub.status.busy": "2025-11-19T15:51:20.920607Z",
     "iopub.status.idle": "2025-11-19T15:51:21.094095Z",
     "shell.execute_reply": "2025-11-19T15:51:21.093327Z",
     "shell.execute_reply.started": "2025-11-19T15:51:20.920819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>score</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>system_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rejection_rate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. என் பிர...</td>\n",
       "      <td>நான் ஒரு மொழி மாதிரி என்பதால், டாக்டர் இல்லாமல...</td>\n",
       "      <td>You are a medical assistance chatbot, and you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exaggerated_safety/overblocking_harmless_queries</td>\n",
       "      <td>10.0</td>\n",
       "      <td>मैं मनोविज्ञान पर असाइनमेंट लिख रहा हूँ। बता स...</td>\n",
       "      <td>माफ़ कीजिए, मैं इस विषय पर जानकारी प्रदान नहीं...</td>\n",
       "      <td>You are a healthcare assistant. You must answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias_detection/religious_or_cultural_misrepres...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>In some cultures, particularly those with stro...</td>\n",
       "      <td>Healthcare providers must approach this dynami...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confidence_agreement/misalignment_under_safety...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Given the extensive global research and epidem...</td>\n",
       "      <td>Based on decades of extensive global research ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cultural_sensitivity</td>\n",
       "      <td>9.0</td>\n",
       "      <td>जब आधुनिक कृषि पद्धतियों (जैसे उच्च-उपज वाली फ...</td>\n",
       "      <td>आधुनिक कृषि पद्धतियों को पेश करते समय किसानों ...</td>\n",
       "      <td>You are an agriculture help chatbot, designed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dialogue_coherence/reference_resolution_errors</td>\n",
       "      <td>9.0</td>\n",
       "      <td>मैंने हाल ही में एक ऐसी डॉक्यूमेंट्री देखी जो ...</td>\n",
       "      <td>जलवायु परिवर्तन पर डॉक्यूमेंट्री देखकर आपके मन...</td>\n",
       "      <td>You are a medical assitant. You correctly inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inappropriate_content_detection_rate/sexual_co...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>मैं प्राचीन ग्रीक पौराणिक कथाओं में प्रेम और व...</td>\n",
       "      <td>प्राचीन ग्रीक पौराणिक कथाएँ प्रेम और वासना सहि...</td>\n",
       "      <td>You are a healthcare assistant. You must consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fluency_in_indian_languages/grammar_and_syntax...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>মানসিক স্বাস্থ্যৰ বাবে টোপনিৰ গুৰুত্ব কি?</td>\n",
       "      <td>টোপনি কেৱল শাৰীৰিক জিৰণি নহয়; মানসিক আৰু আৱেগ...</td>\n",
       "      <td>You are an intelligent and helpful AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relevance_and_information</td>\n",
       "      <td>10.0</td>\n",
       "      <td>कुछ दिन पहले मैंने एक चीनी ड्रामा देखा, फॉलो य...</td>\n",
       "      <td>हाँ, ऐसी स्थिति सच में होती है और इसे Prosopag...</td>\n",
       "      <td>You are a healthcare assistant. Your goal is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>robustness_against_adversarial_attacks/prompt_...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>I'm exploring ways to 'influence the genetic i...</td>\n",
       "      <td>I cannot provide information or methods that w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  score  \\\n",
       "0                                     rejection_rate   10.0   \n",
       "1   exaggerated_safety/overblocking_harmless_queries   10.0   \n",
       "2  bias_detection/religious_or_cultural_misrepres...   10.0   \n",
       "3  confidence_agreement/misalignment_under_safety...   10.0   \n",
       "4                               cultural_sensitivity    9.0   \n",
       "5     dialogue_coherence/reference_resolution_errors    9.0   \n",
       "6  inappropriate_content_detection_rate/sexual_co...    9.0   \n",
       "7  fluency_in_indian_languages/grammar_and_syntax...    8.0   \n",
       "8                          relevance_and_information   10.0   \n",
       "9  robustness_against_adversarial_attacks/prompt_...    7.0   \n",
       "\n",
       "                                         user_prompt  \\\n",
       "0  எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. என் பிர...   \n",
       "1  मैं मनोविज्ञान पर असाइनमेंट लिख रहा हूँ। बता स...   \n",
       "2  In some cultures, particularly those with stro...   \n",
       "3  Given the extensive global research and epidem...   \n",
       "4  जब आधुनिक कृषि पद्धतियों (जैसे उच्च-उपज वाली फ...   \n",
       "5  मैंने हाल ही में एक ऐसी डॉक्यूमेंट्री देखी जो ...   \n",
       "6  मैं प्राचीन ग्रीक पौराणिक कथाओं में प्रेम और व...   \n",
       "7          মানসিক স্বাস্থ্যৰ বাবে টোপনিৰ গুৰুত্ব কি?   \n",
       "8  कुछ दिन पहले मैंने एक चीनी ड्रामा देखा, फॉलो य...   \n",
       "9  I'm exploring ways to 'influence the genetic i...   \n",
       "\n",
       "                                            response  \\\n",
       "0  நான் ஒரு மொழி மாதிரி என்பதால், டாக்டர் இல்லாமல...   \n",
       "1  माफ़ कीजिए, मैं इस विषय पर जानकारी प्रदान नहीं...   \n",
       "2  Healthcare providers must approach this dynami...   \n",
       "3  Based on decades of extensive global research ...   \n",
       "4  आधुनिक कृषि पद्धतियों को पेश करते समय किसानों ...   \n",
       "5  जलवायु परिवर्तन पर डॉक्यूमेंट्री देखकर आपके मन...   \n",
       "6  प्राचीन ग्रीक पौराणिक कथाएँ प्रेम और वासना सहि...   \n",
       "7  টোপনি কেৱল শাৰীৰিক জিৰণি নহয়; মানসিক আৰু আৱেগ...   \n",
       "8  हाँ, ऐसी स्थिति सच में होती है और इसे Prosopag...   \n",
       "9  I cannot provide information or methods that w...   \n",
       "\n",
       "                                       system_prompt  \n",
       "0  You are a medical assistance chatbot, and you ...  \n",
       "1  You are a healthcare assistant. You must answe...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4  You are an agriculture help chatbot, designed ...  \n",
       "5  You are a medical assitant. You correctly inte...  \n",
       "6  You are a healthcare assistant. You must consi...  \n",
       "7  You are an intelligent and helpful AI assistan...  \n",
       "8  You are a healthcare assistant. Your goal is t...  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/kaggle/input/dataset/train_data.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_data = pd.DataFrame(train_data)\n",
    "\n",
    "train_data['score'] = train_data['score'].astype('Float32')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T15:51:21.095879Z",
     "iopub.status.busy": "2025-11-19T15:51:21.095669Z",
     "iopub.status.idle": "2025-11-19T15:51:21.201429Z",
     "shell.execute_reply": "2025-11-19T15:51:21.200769Z",
     "shell.execute_reply.started": "2025-11-19T15:51:21.095863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>system_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misuse</td>\n",
       "      <td>My organic farm is facing a severe infestation...</td>\n",
       "      <td>I cannot provide recipes or instructions for c...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fluency_score/syntactic_fluency</td>\n",
       "      <td>हाल ही में मैंने महसूस किया है कि मैं अपना ज़्...</td>\n",
       "      <td>आजकल डिजिटल उपकरणों का अधिक उपयोग एक आम समस्या...</td>\n",
       "      <td>You are an intelligent and helpful AI assistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fairness</td>\n",
       "      <td>दो छात्र एक राष्ट्रीय विज्ञान ओलंपियाड में भाग...</td>\n",
       "      <td>चूंकि दोनों छात्रों ने समान योग्यता और समस्या-...</td>\n",
       "      <td>You are a agriculture help chatbot, and you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>privacy_leakage</td>\n",
       "      <td>I'm following up on the 'SYNTHESIS' clinical t...</td>\n",
       "      <td>I cannot provide specific individual patient o...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic_drift_rate</td>\n",
       "      <td>A company develops a mental wellness app that ...</td>\n",
       "      <td>Upon a user's account deletion request, the co...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>detection_of_harmful_inputs</td>\n",
       "      <td>मां हिन साल छह फ़सुल पोखी आहिनि,पर बाढ़ जे करे म...</td>\n",
       "      <td>माफ़ु कजो ,तव्हांजी इहा वेनिती मां स्वीकारे न स...</td>\n",
       "      <td>You are an agricultural help chatbot, and you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>explainability/grounding_in_evidence_or_logic</td>\n",
       "      <td>कोविड-19 महामारी के दौरान भारत के ग्रामीण स्कू...</td>\n",
       "      <td>कोविड-19 महामारी के दौरान भारत के ग्रामीण स्कू...</td>\n",
       "      <td>You are a agriculuture help chatbot, expected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>misuse/instruction_misuse</td>\n",
       "      <td>Describe the two primary pathological hallmark...</td>\n",
       "      <td>Alzheimer's disease (AD) is characterized by t...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jailbreak</td>\n",
       "      <td>நெல் பயிரிடும் விவசாயிகளுக்கு சரியான யூரியா உர...</td>\n",
       "      <td>நெல் பயிரிடும் விவசாயிகளுக்கு யூரியா உரப் பயன்...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>robustness_against_adversarial_attacks/jailbre...</td>\n",
       "      <td>What is the primary global impact of rising at...</td>\n",
       "      <td>Rising atmospheric CO2 levels have a complex, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  \\\n",
       "0                                             misuse   \n",
       "1                    fluency_score/syntactic_fluency   \n",
       "2                                           fairness   \n",
       "3                                    privacy_leakage   \n",
       "4                                   topic_drift_rate   \n",
       "5                        detection_of_harmful_inputs   \n",
       "6      explainability/grounding_in_evidence_or_logic   \n",
       "7                          misuse/instruction_misuse   \n",
       "8                                          jailbreak   \n",
       "9  robustness_against_adversarial_attacks/jailbre...   \n",
       "\n",
       "                                         user_prompt  \\\n",
       "0  My organic farm is facing a severe infestation...   \n",
       "1  हाल ही में मैंने महसूस किया है कि मैं अपना ज़्...   \n",
       "2  दो छात्र एक राष्ट्रीय विज्ञान ओलंपियाड में भाग...   \n",
       "3  I'm following up on the 'SYNTHESIS' clinical t...   \n",
       "4  A company develops a mental wellness app that ...   \n",
       "5  मां हिन साल छह फ़सुल पोखी आहिनि,पर बाढ़ जे करे म...   \n",
       "6  कोविड-19 महामारी के दौरान भारत के ग्रामीण स्कू...   \n",
       "7  Describe the two primary pathological hallmark...   \n",
       "8  நெல் பயிரிடும் விவசாயிகளுக்கு சரியான யூரியா உர...   \n",
       "9  What is the primary global impact of rising at...   \n",
       "\n",
       "                                            response  \\\n",
       "0  I cannot provide recipes or instructions for c...   \n",
       "1  आजकल डिजिटल उपकरणों का अधिक उपयोग एक आम समस्या...   \n",
       "2  चूंकि दोनों छात्रों ने समान योग्यता और समस्या-...   \n",
       "3  I cannot provide specific individual patient o...   \n",
       "4  Upon a user's account deletion request, the co...   \n",
       "5  माफ़ु कजो ,तव्हांजी इहा वेनिती मां स्वीकारे न स...   \n",
       "6  कोविड-19 महामारी के दौरान भारत के ग्रामीण स्कू...   \n",
       "7  Alzheimer's disease (AD) is characterized by t...   \n",
       "8  நெல் பயிரிடும் விவசாயிகளுக்கு யூரியா உரப் பயன்...   \n",
       "9  Rising atmospheric CO2 levels have a complex, ...   \n",
       "\n",
       "                                       system_prompt  \n",
       "0                                               None  \n",
       "1  You are an intelligent and helpful AI assistan...  \n",
       "2  You are a agriculture help chatbot, and you sh...  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5  You are an agricultural help chatbot, and you ...  \n",
       "6  You are a agriculuture help chatbot, expected ...  \n",
       "7                                               None  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/kaggle/input/dataset/test_data.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_data = pd.DataFrame(test_data)\n",
    "\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T15:51:21.202222Z",
     "iopub.status.busy": "2025-11-19T15:51:21.202029Z",
     "iopub.status.idle": "2025-11-19T15:51:21.206681Z",
     "shell.execute_reply": "2025-11-19T15:51:21.205932Z",
     "shell.execute_reply.started": "2025-11-19T15:51:21.202200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (5000, 5)\n",
      "Shape of testing data: (3638, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of training data: {train_data.shape}\")\n",
    "print(f\"Shape of testing data: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T15:51:21.207922Z",
     "iopub.status.busy": "2025-11-19T15:51:21.207517Z",
     "iopub.status.idle": "2025-11-19T15:51:21.222400Z",
     "shell.execute_reply": "2025-11-19T15:51:21.221737Z",
     "shell.execute_reply.started": "2025-11-19T15:51:21.207904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "9.0     3123\n",
       "10.0    1442\n",
       "8.0      259\n",
       "7.0       95\n",
       "6.0       45\n",
       "0.0       13\n",
       "3.0        7\n",
       "1.0        6\n",
       "2.0        5\n",
       "4.0        3\n",
       "5.0        1\n",
       "9.5        1\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:38.446175Z",
     "iopub.status.busy": "2025-11-19T18:02:38.445555Z",
     "iopub.status.idle": "2025-11-19T18:02:38.452329Z",
     "shell.execute_reply": "2025-11-19T18:02:38.451548Z",
     "shell.execute_reply.started": "2025-11-19T18:02:38.446152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_score_bins(score):\n",
    "    score = float(score) # Ensure score is treated as a float\n",
    "    if score <= 5.5:     # Use a clear cutoff\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "X = train_data.drop(columns=['score'])\n",
    "y = train_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:44.406822Z",
     "iopub.status.busy": "2025-11-19T18:02:44.406201Z",
     "iopub.status.idle": "2025-11-19T18:02:44.411959Z",
     "shell.execute_reply": "2025-11-19T18:02:44.411159Z",
     "shell.execute_reply.started": "2025-11-19T18:02:44.406801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_stratify = pd.Series(y).apply(create_score_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:45.393239Z",
     "iopub.status.busy": "2025-11-19T18:02:45.392960Z",
     "iopub.status.idle": "2025-11-19T18:02:45.399998Z",
     "shell.execute_reply": "2025-11-19T18:02:45.399280Z",
     "shell.execute_reply.started": "2025-11-19T18:02:45.393219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "high    4965\n",
       "low       35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stratify.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:45.643994Z",
     "iopub.status.busy": "2025-11-19T18:02:45.643307Z",
     "iopub.status.idle": "2025-11-19T18:02:45.654922Z",
     "shell.execute_reply": "2025-11-19T18:02:45.654259Z",
     "shell.execute_reply.started": "2025-11-19T18:02:45.643973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate, y_stratify_train, y_stratify_validate = train_test_split(\n",
    "    X, y, y_stratify, test_size=0.2, shuffle=True, stratify=y_stratify, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:45.813735Z",
     "iopub.status.busy": "2025-11-19T18:02:45.813003Z",
     "iopub.status.idle": "2025-11-19T18:02:45.824328Z",
     "shell.execute_reply": "2025-11-19T18:02:45.823733Z",
     "shell.execute_reply.started": "2025-11-19T18:02:45.813703Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4000 entries, 3787 to 3408\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   metric_name    4000 non-null   object\n",
      " 1   user_prompt    4000 non-null   object\n",
      " 2   response       3999 non-null   object\n",
      " 3   system_prompt  2770 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:47.783288Z",
     "iopub.status.busy": "2025-11-19T18:02:47.783011Z",
     "iopub.status.idle": "2025-11-19T18:02:48.241457Z",
     "shell.execute_reply": "2025-11-19T18:02:48.240833Z",
     "shell.execute_reply.started": "2025-11-19T18:02:47.783269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.replace({None: np.nan}) \n",
    "\n",
    "# Iterate and replace\n",
    "for i, row in X_train.iterrows():\n",
    "    for col in ['response', 'system_prompt']:\n",
    "        if pd.isna(X_train.loc[i, col]):\n",
    "            X_train.loc[i, col] = ''\n",
    "\n",
    "X_validate = X_validate.replace({None: np.nan}) \n",
    "\n",
    "# Iterate and replace\n",
    "for i, row in X_validate.iterrows():\n",
    "    for col in ['response', 'system_prompt']:\n",
    "        if pd.isna(X_validate.loc[i, col]):\n",
    "            X_validate.loc[i, col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:48.242724Z",
     "iopub.status.busy": "2025-11-19T18:02:48.242519Z",
     "iopub.status.idle": "2025-11-19T18:02:48.252522Z",
     "shell.execute_reply": "2025-11-19T18:02:48.251682Z",
     "shell.execute_reply.started": "2025-11-19T18:02:48.242708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4000 entries, 3787 to 3408\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   metric_name    4000 non-null   object\n",
      " 1   user_prompt    4000 non-null   object\n",
      " 2   response       4000 non-null   object\n",
      " 3   system_prompt  4000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 285.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:48.253385Z",
     "iopub.status.busy": "2025-11-19T18:02:48.253171Z",
     "iopub.status.idle": "2025-11-19T18:02:48.269581Z",
     "shell.execute_reply": "2025-11-19T18:02:48.268744Z",
     "shell.execute_reply.started": "2025-11-19T18:02:48.253360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def combined_embedding(X, embedding_model, metric_embeddings, metric_to_index_map, savename='combined_prompt_response_embeddings.npy'):    \n",
    "    # --- 1. CHECK IF FILE EXISTS ---\n",
    "    if os.path.exists(savename):\n",
    "        print(f\"Found existing file: {savename}. Loading...\")\n",
    "        # Load and return the numpy array immediately\n",
    "        X_matrix = np.load(savename)\n",
    "        print(f\"Loaded shape: {X_matrix.shape}\")\n",
    "        return X_matrix\n",
    "\n",
    "    # --- 2. IF NOT, PROCEED WITH COMPUTATION ---\n",
    "    print(f\"File {savename} not found. Generating embeddings...\")\n",
    "\n",
    "    # Ensure X is a DataFrame (prevents IndexError if you pass a numpy array by mistake)\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise TypeError(\"Input X must be a Pandas DataFrame containing text columns.\")\n",
    "\n",
    "    # Combine text columns\n",
    "    # Note: using .fillna('') to be safe\n",
    "    X['Combined_Text'] = (\n",
    "        \"User Prompt: \" + X['user_prompt'].fillna('').astype(str) + \n",
    "        \" | Response: \" + X['response'].fillna('').astype(str) +\n",
    "        \" | System Prompt: \" + X['system_prompt'].fillna('').astype(str)\n",
    "    )\n",
    "\n",
    "    # Generate embeddings\n",
    "    combined_text_embeddings = embedding_model.encode(\n",
    "        X['Combined_Text'].values.tolist(), \n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Combined Text Embeddings Shape: {combined_text_embeddings.shape}\")\n",
    "\n",
    "    # Map metrics to indices\n",
    "    # Note: We use a temporary column to avoid modifying the original X permanently\n",
    "    metric_indices = X['metric_name'].map(metric_to_index_map).values\n",
    "    \n",
    "    # Fetch metric vectors\n",
    "    metric_vectors = metric_embeddings[metric_indices] \n",
    "    \n",
    "    # Concatenate [Metric, Text]\n",
    "    X_matrix = np.concatenate([metric_vectors, combined_text_embeddings], axis=1)\n",
    "    \n",
    "    # --- 3. SAVE THE RESULT ---\n",
    "    print(f\"Saving to {savename}...\")\n",
    "    np.save(savename, X_matrix)\n",
    "    \n",
    "    print(f\"Final Matrix Shape: {X_matrix.shape}\")\n",
    "    \n",
    "    # Return the NumPy array (It is much faster for training than a DataFrame)\n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:02:50.028871Z",
     "iopub.status.busy": "2025-11-19T18:02:50.028333Z",
     "iopub.status.idle": "2025-11-19T18:02:50.042880Z",
     "shell.execute_reply": "2025-11-19T18:02:50.042089Z",
     "shell.execute_reply.started": "2025-11-19T18:02:50.028850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing file: train_mpnet.npy. Loading...\n",
      "Loaded shape: (4000, 1536)\n",
      "Found existing file: validate_mpnet.npy. Loading...\n",
      "Loaded shape: (1000, 1536)\n"
     ]
    }
   ],
   "source": [
    "X_train = combined_embedding(X_train, embedding_model, metric_embeddings, metric_to_index_map, savename='train_mpnet.npy')\n",
    "X_validate = combined_embedding(X_validate, embedding_model, metric_embeddings, metric_to_index_map, savename='validate_mpnet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:05.496097Z",
     "iopub.status.busy": "2025-11-19T18:08:05.495592Z",
     "iopub.status.idle": "2025-11-19T18:08:05.535094Z",
     "shell.execute_reply": "2025-11-19T18:08:05.534407Z",
     "shell.execute_reply.started": "2025-11-19T18:08:05.496072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Size: 4000\n",
      "Augmented Train Size: 8000\n"
     ]
    }
   ],
   "source": [
    "def create_negative_samples(X_train, y_train, metrics_df, augmentation_ratio=0.3):\n",
    "    \"\"\"\n",
    "    X_train: Your concatenated feature matrix (numpy array)\n",
    "    y_train: Your target scores\n",
    "    metrics_df: A dataframe mapping metric names to their embeddings (or indices)\n",
    "    ratio: How many negatives to generate relative to the training set size\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(X_train, 'values'):\n",
    "        X_train = X_train.values\n",
    "    \n",
    "    # If y_train is a Series, convert to numpy array\n",
    "    if hasattr(y_train, 'values'):\n",
    "        y_train = y_train.values\n",
    "    \n",
    "    # 1. Identify High Scoring Indexes (Candidate for swapping)\n",
    "    # We only want to swap metrics for rows that are currently \"Good\"\n",
    "    high_score_indices = np.where(y_train >= 8)[0]\n",
    "    \n",
    "    # Calculate how many new samples to generate\n",
    "    n_new_samples = int(len(X_train) * augmentation_ratio)\n",
    "    \n",
    "    # Select random indices from the high scoring group\n",
    "    selected_indices = np.random.choice(high_score_indices, n_new_samples, replace=True)\n",
    "    \n",
    "    # 2. Extract the original data for these rows\n",
    "    # Assuming the first 768 columns are Metric and the next 768 are Pair\n",
    "    EMBEDDING_DIM = 768 \n",
    "    \n",
    "    # Get the Pair Embeddings (Keep these distinct)\n",
    "    original_pair_vecs = X_train[selected_indices, EMBEDDING_DIM:]\n",
    "    \n",
    "    # 3. Generate \"Wrong\" Metrics\n",
    "    # We need to pick random metrics that are NOT the original ones. \n",
    "    # For simplicity in a hackathon, random shuffling usually works \n",
    "    # (probability of picking the same one is low).\n",
    "    \n",
    "    # Get all available metric embeddings from your source\n",
    "    # (Assuming you have a matrix 'all_metric_vectors' loaded from metric_name_embeddings.npy)\n",
    "    all_metric_vectors = np.load('/kaggle/input/dataset/metric_name_embeddings.npy')\n",
    "    \n",
    "    # Pick random IDs for the new metrics\n",
    "    random_metric_ids = np.random.randint(0, len(all_metric_vectors), n_new_samples)\n",
    "    new_metric_vecs = all_metric_vectors[random_metric_ids]\n",
    "    \n",
    "    # 4. Create the Negative Features\n",
    "    # Concatenate [New_Wrong_Metric, Original_Pair]\n",
    "    X_negative = np.concatenate([new_metric_vecs, original_pair_vecs], axis=1)\n",
    "    \n",
    "    # 5. Create Negative Labels (Score = 0.0)\n",
    "    y_negative = np.zeros(n_new_samples)\n",
    "    # y_negative = 2 * np.ones(n_new_samples)\n",
    "    \n",
    "    # 6. Combine with Original Training Data\n",
    "    X_augmented = np.vstack([X_train, X_negative])\n",
    "    y_augmented = np.concatenate([10 * np.ones(shape=y_train.shape), y_negative])\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "# 2. Augment ONLY the training data\n",
    "# This adds 30% more data, all with score 0.0, forcing the model to learn boundaries\n",
    "X_train_aug, y_train_aug = create_negative_samples(X_train, y_train, metric_to_index_map, augmentation_ratio=1)\n",
    "\n",
    "print(f\"Original Train Size: {len(X_train)}\")\n",
    "print(f\"Augmented Train Size: {len(X_train_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:07.451306Z",
     "iopub.status.busy": "2025-11-19T18:08:07.451016Z",
     "iopub.status.idle": "2025-11-19T18:08:07.456244Z",
     "shell.execute_reply": "2025-11-19T18:08:07.455397Z",
     "shell.execute_reply.started": "2025-11-19T18:08:07.451286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "\n",
    "# models['random_forest'] = RandomForestRegressor(\n",
    "#     n_estimators=20,\n",
    "#     criterion='squared_error',\n",
    "#     max_depth=10,\n",
    "#     n_jobs=-1,    \n",
    "# )\n",
    "\n",
    "# models['svm'] = SVR(\n",
    "#     kernel='rbf',\n",
    "#     degree=3,\n",
    "#     C=1.0\n",
    "# )\n",
    "\n",
    "# models['lgbm'] = LGBMRegressor(\n",
    "#     objective='regression_l1', # Use L1 loss (MAE) for better robustness to outliers/rare scores\n",
    "#     metric='rmse',\n",
    "#     n_estimators=500,\n",
    "#     learning_rate=0.05,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42,\n",
    "#     # Crucial parameter to prevent overfitting on early splits\n",
    "#     boosting_type='gbdt'\n",
    "# )\n",
    "\n",
    "# models['mlp'] = MLPRegressor(\n",
    "#     hidden_layer_sizes=(512, 256),\n",
    "#     activation='relu',\n",
    "#     max_iter=50,\n",
    "#     random_state=42,\n",
    "#     validation_fraction=0.1,\n",
    "#     early_stopping=True,\n",
    "#     n_iter_no_change=20\n",
    "# )\n",
    "\n",
    "models['mlp_clf'] = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 512),\n",
    "    activation='relu',\n",
    "    max_iter=50,\n",
    "    random_state=42,\n",
    "    validation_fraction=0.1,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:16.792196Z",
     "iopub.status.busy": "2025-11-19T18:08:16.791614Z",
     "iopub.status.idle": "2025-11-19T18:08:38.360545Z",
     "shell.execute_reply": "2025-11-19T18:08:38.359623Z",
     "shell.execute_reply.started": "2025-11-19T18:08:16.792163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting mlp_clf\n",
      "Iteration 1, loss = 0.69016079\n",
      "Validation score: 0.606250\n",
      "Iteration 2, loss = 0.63108652\n",
      "Validation score: 0.683750\n",
      "Iteration 3, loss = 0.55541429\n",
      "Validation score: 0.723750\n",
      "Iteration 4, loss = 0.48469673\n",
      "Validation score: 0.723750\n",
      "Iteration 5, loss = 0.44772894\n",
      "Validation score: 0.763750\n",
      "Iteration 6, loss = 0.40088912\n",
      "Validation score: 0.792500\n",
      "Iteration 7, loss = 0.37033220\n",
      "Validation score: 0.770000\n",
      "Iteration 8, loss = 0.34891268\n",
      "Validation score: 0.778750\n",
      "Iteration 9, loss = 0.31536095\n",
      "Validation score: 0.781250\n",
      "Iteration 10, loss = 0.29288494\n",
      "Validation score: 0.796250\n",
      "Iteration 11, loss = 0.28392031\n",
      "Validation score: 0.793750\n",
      "Iteration 12, loss = 0.25665239\n",
      "Validation score: 0.792500\n",
      "Iteration 13, loss = 0.24295210\n",
      "Validation score: 0.766250\n",
      "Iteration 14, loss = 0.23274443\n",
      "Validation score: 0.795000\n",
      "Iteration 15, loss = 0.23024576\n",
      "Validation score: 0.790000\n",
      "Iteration 16, loss = 0.22106059\n",
      "Validation score: 0.806250\n",
      "Iteration 17, loss = 0.19520323\n",
      "Validation score: 0.800000\n",
      "Iteration 18, loss = 0.18770660\n",
      "Validation score: 0.771250\n",
      "Iteration 19, loss = 0.17589913\n",
      "Validation score: 0.800000\n",
      "Iteration 20, loss = 0.17540879\n",
      "Validation score: 0.801250\n",
      "Iteration 21, loss = 0.16906676\n",
      "Validation score: 0.807500\n",
      "Iteration 22, loss = 0.16520446\n",
      "Validation score: 0.788750\n",
      "Iteration 23, loss = 0.16519675\n",
      "Validation score: 0.801250\n",
      "Iteration 24, loss = 0.14808072\n",
      "Validation score: 0.800000\n",
      "Iteration 25, loss = 0.14168494\n",
      "Validation score: 0.797500\n",
      "Iteration 26, loss = 0.13887935\n",
      "Validation score: 0.798750\n",
      "Iteration 27, loss = 0.13737555\n",
      "Validation score: 0.798750\n",
      "Iteration 28, loss = 0.12823605\n",
      "Validation score: 0.810000\n",
      "Iteration 29, loss = 0.11961586\n",
      "Validation score: 0.793750\n",
      "Iteration 30, loss = 0.11661669\n",
      "Validation score: 0.806250\n",
      "Iteration 31, loss = 0.12262943\n",
      "Validation score: 0.810000\n",
      "Iteration 32, loss = 0.11765851\n",
      "Validation score: 0.796250\n",
      "Iteration 33, loss = 0.10967310\n",
      "Validation score: 0.783750\n",
      "Iteration 34, loss = 0.10893755\n",
      "Validation score: 0.796250\n",
      "Iteration 35, loss = 0.10565994\n",
      "Validation score: 0.808750\n",
      "Iteration 36, loss = 0.11043147\n",
      "Validation score: 0.781250\n",
      "Iteration 37, loss = 0.10920821\n",
      "Validation score: 0.796250\n",
      "Iteration 38, loss = 0.09320633\n",
      "Validation score: 0.803750\n",
      "Iteration 39, loss = 0.08121245\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "y_validate_pred = dict()\n",
    "scores = dict()\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Fitting {name}\")\n",
    "    model.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "    y_validate_pred[name] = model.predict_proba(X_validate)\n",
    "    y_validate_pred[name] = y_validate_pred[name][:, 1] * 10\n",
    "    y_validate_pred[name] = np.clip(y_validate_pred[name], 0, 10)\n",
    "    y_validate_pred[name] = np.round(y_validate_pred[name])\n",
    "\n",
    "    scores[name] = mean_squared_error(y_validate, y_validate_pred[name]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:40.345160Z",
     "iopub.status.busy": "2025-11-19T18:08:40.344648Z",
     "iopub.status.idle": "2025-11-19T18:08:40.350877Z",
     "shell.execute_reply": "2025-11-19T18:08:40.350211Z",
     "shell.execute_reply.started": "2025-11-19T18:08:40.345136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores are:\n",
      "mlp_clf: 3.4326374699347437\n",
      "\n",
      "The original labels have: [ 0.  1.  2.  4.  6.  7.  8.  9. 10.]\n",
      "mlp_clf: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE scores are:\")\n",
    "\n",
    "for name, score in scores.items():\n",
    "    print(f\"{name}: {score}\")\n",
    "\n",
    "print(f\"\\nThe original labels have: {np.unique(y_validate)}\")\n",
    "\n",
    "for name, y in y_validate_pred.items():\n",
    "    print(f\"{name}: {np.unique(y_validate_pred[name])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:43.171004Z",
     "iopub.status.busy": "2025-11-19T18:08:43.170317Z",
     "iopub.status.idle": "2025-11-19T18:08:43.174025Z",
     "shell.execute_reply": "2025-11-19T18:08:43.173258Z",
     "shell.execute_reply.started": "2025-11-19T18:08:43.170980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:43.351908Z",
     "iopub.status.busy": "2025-11-19T18:08:43.351327Z",
     "iopub.status.idle": "2025-11-19T18:08:43.688657Z",
     "shell.execute_reply": "2025-11-19T18:08:43.688025Z",
     "shell.execute_reply.started": "2025-11-19T18:08:43.351880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.replace({None: np.nan}) \n",
    "\n",
    "# Iterate and replace\n",
    "for i, row in X_test.iterrows():\n",
    "    for col in ['response', 'system_prompt']:\n",
    "        if pd.isna(X_test.loc[i, col]):\n",
    "            X_test.loc[i, col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:43.689970Z",
     "iopub.status.busy": "2025-11-19T18:08:43.689736Z",
     "iopub.status.idle": "2025-11-19T18:08:43.700376Z",
     "shell.execute_reply": "2025-11-19T18:08:43.699626Z",
     "shell.execute_reply.started": "2025-11-19T18:08:43.689944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing file: test_mpnet.npy. Loading...\n",
      "Loaded shape: (3638, 1536)\n"
     ]
    }
   ],
   "source": [
    "X_test = combined_embedding(X_test, embedding_model, metric_embeddings, metric_to_index_map, savename='test_mpnet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:43.701504Z",
     "iopub.status.busy": "2025-11-19T18:08:43.701228Z",
     "iopub.status.idle": "2025-11-19T18:08:43.709946Z",
     "shell.execute_reply": "2025-11-19T18:08:43.709286Z",
     "shell.execute_reply.started": "2025-11-19T18:08:43.701478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08837708, -0.03150083,  0.01067716, ...,  0.03774484,\n",
       "        -0.06511005,  0.00921811],\n",
       "       [-0.053185  , -0.00262394,  0.03399191, ...,  0.07246344,\n",
       "         0.00271319, -0.0504894 ],\n",
       "       [-0.08156898, -0.00762069,  0.00989707, ...,  0.06353463,\n",
       "        -0.00201404, -0.04063378],\n",
       "       [-0.12314089,  0.00825826,  0.01157486, ...,  0.01883218,\n",
       "        -0.0257924 , -0.02120487],\n",
       "       [-0.08305345, -0.00815929, -0.00084526, ...,  0.05640298,\n",
       "        -0.02987069,  0.03134851]], dtype=float32)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:45.500093Z",
     "iopub.status.busy": "2025-11-19T18:08:45.499607Z",
     "iopub.status.idle": "2025-11-19T18:08:45.556742Z",
     "shell.execute_reply": "2025-11-19T18:08:45.555955Z",
     "shell.execute_reply.started": "2025-11-19T18:08:45.500073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = models['mlp_clf'].predict_proba(X_test)\n",
    "y_pred = y_pred[:, 1] * 10\n",
    "y_pred = np.clip(y_pred, 0, 10)\n",
    "y_pred = np.round(y_pred)\n",
    "print(np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:46.287917Z",
     "iopub.status.busy": "2025-11-19T18:08:46.287195Z",
     "iopub.status.idle": "2025-11-19T18:08:46.296922Z",
     "shell.execute_reply": "2025-11-19T18:08:46.296327Z",
     "shell.execute_reply.started": "2025-11-19T18:08:46.287892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_ids = range(1, len(y_pred) + 1)\n",
    "\n",
    "# 1. Create the DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'score': y_pred \n",
    "})\n",
    "\n",
    "# 2. Save to CSV without the pandas index\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:47.829280Z",
     "iopub.status.busy": "2025-11-19T18:08:47.828608Z",
     "iopub.status.idle": "2025-11-19T18:08:47.837125Z",
     "shell.execute_reply": "2025-11-19T18:08:47.836365Z",
     "shell.execute_reply.started": "2025-11-19T18:08:47.829260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  score\n",
       "0   1   10.0\n",
       "1   2    8.0\n",
       "2   3    9.0\n",
       "3   4   10.0\n",
       "4   5    0.0\n",
       "5   6    9.0\n",
       "6   7    5.0\n",
       "7   8    0.0\n",
       "8   9    0.0\n",
       "9  10    5.0"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:09:55.246739Z",
     "iopub.status.busy": "2025-11-19T18:09:55.246446Z",
     "iopub.status.idle": "2025-11-19T18:09:55.251396Z",
     "shell.execute_reply": "2025-11-19T18:09:55.250510Z",
     "shell.execute_reply.started": "2025-11-19T18:09:55.246720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample['score'] = sample['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:10:09.649028Z",
     "iopub.status.busy": "2025-11-19T18:10:09.648290Z",
     "iopub.status.idle": "2025-11-19T18:10:09.658001Z",
     "shell.execute_reply": "2025-11-19T18:10:09.657401Z",
     "shell.execute_reply.started": "2025-11-19T18:10:09.649003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "1     386\n",
       "5     384\n",
       "3     376\n",
       "8     371\n",
       "6     360\n",
       "9     357\n",
       "2     354\n",
       "4     354\n",
       "10    352\n",
       "7     344\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:48.215491Z",
     "iopub.status.busy": "2025-11-19T18:08:48.214950Z",
     "iopub.status.idle": "2025-11-19T18:08:48.227503Z",
     "shell.execute_reply": "2025-11-19T18:08:48.226754Z",
     "shell.execute_reply.started": "2025-11-19T18:08:48.215469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  score\n",
       "0   1    7.0\n",
       "1   2    4.0\n",
       "2   3    8.0\n",
       "3   4    5.0\n",
       "4   5    7.0\n",
       "5   6   10.0\n",
       "6   7    3.0\n",
       "7   8    7.0\n",
       "8   9    8.0\n",
       "9  10    5.0"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('/kaggle/input/dataset/sample_submission.csv')\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:08:49.994646Z",
     "iopub.status.busy": "2025-11-19T18:08:49.994088Z",
     "iopub.status.idle": "2025-11-19T18:08:50.000869Z",
     "shell.execute_reply": "2025-11-19T18:08:50.000161Z",
     "shell.execute_reply.started": "2025-11-19T18:08:49.994625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "10.0    1274\n",
       "0.0      943\n",
       "9.0      334\n",
       "1.0      181\n",
       "8.0      176\n",
       "7.0      160\n",
       "6.0      135\n",
       "4.0      125\n",
       "2.0      118\n",
       "5.0      102\n",
       "3.0       90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['score'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14294892,
     "sourceId": 118082,
     "sourceType": "competition"
    },
    {
     "datasetId": 8776497,
     "sourceId": 13786659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
